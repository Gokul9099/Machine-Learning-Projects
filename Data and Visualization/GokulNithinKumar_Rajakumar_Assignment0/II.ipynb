{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 0 Chapter Summarization\n",
    "Name: Gokul Nithin Kumar Rajakumar\n",
    "Student ID: 801082252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A Linear Algebra.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Scalars\n",
    "  It is just a single number. It just contains values.\n",
    "\n",
    "## Vectors\n",
    "They are  ones which contains both values and direction.\n",
    "\n",
    "## Matrices.\n",
    "It is  a 2D array represented by A m,n, where, m-> no of columns\n",
    "m-> no of rows\n",
    "\n",
    "## Tensors\n",
    "It is nothing but the dot product that maps two vectors to a scalar\n",
    "\n",
    "# 2.2 Multiplying matrices and vectors\n",
    "\tMatrix multiplication is defined by,\n",
    "\t\tC i,j= ∑_k▒〖A i,k  B k,j〗\n",
    "\n",
    "Useful Operations in matrix product\n",
    "\tA(B+C)=AB+AC\n",
    "\tA(BC)=(AB)C\n",
    "\tAB=BA    -> does not hold true always\n",
    "\tX(transpose)Y=Y(transpose)X\n",
    "\n",
    "# 2.3 Identity Matrix\n",
    "    \tIt is a matrix that when multiplied with a matix leads to the same matrix.\n",
    "        Inverse Matrix\n",
    "\tA matrix when multiplied with its inverse matrix leads to identity matrix.\n",
    "\tA(inverse) A=I\n",
    "\n",
    "# 2.4 Linear Dependence and Span\n",
    "\tThe span of a vector is the set of points that can be obtained by linear combination of original vector.\n",
    "\n",
    "## Linear Dependence: \n",
    "\tIf a vector in the set is a linear combination of another vector in the set of vectors.\n",
    "\n",
    "# 2.5 Norms:\n",
    "\n",
    "\tNorms actually measures the size of the vectors. IOt is given by Lp,\n",
    "\n",
    "\t\t\t||X||p= |(|x|)|p= ∑_i▒〖[|Xi|p/〗](1/p)/\n",
    "\t\t\tP∈R, P≥1\n",
    "    The L2/ norm with p=2 is known as Euclidean norm.\n",
    "    The L1/ norm |(|x|)|1= ∑_i▒〖[|Xi|〗 \n",
    "\n",
    "    is commonly used in ML when difference between zero and non-zero elements is very important.\n",
    "\n",
    "    The dot product of two vectors can be re-written in terms of norms as- \n",
    "\n",
    "       XT/= |(|X|)|  /2 ||Y|| cos∅\n",
    "\n",
    "# 2.6  Special kinds of matrices and vectors:\n",
    "## Diagonal Matrix:\n",
    "      A matrix ‘D’ is diagonal if and only if \n",
    "\tD/(i,j) =0  i≠j\n",
    "## Useful Operations:\n",
    "\tDiag(V) x= dot product(x,x)\n",
    "\tDiag (V (inverse))= diag[[1/v1,1/v2,……1/vn]]T/\n",
    "\n",
    "\n",
    "## Symmetric Matrix:\n",
    "\n",
    "A =AT/\n",
    "It is a matrix that is equal to its own transpose.\n",
    "Vectors are orthogonal if XT/ Y=0. If they have non zero norms then we can conclude that they are perpendicular.\n",
    "\n",
    "\n",
    "\n",
    "## Orthogonal Matrix:\n",
    "AT/ A=AA T/=I\n",
    "\n",
    "# 2.7  Eigen Decomposition:\n",
    " \tEigen vector of a square matrix A is a non zero vector ‘v’ such that multiplication of ‘A’ alters only the scale of ‘v’ ie.\n",
    "\tAv=αv\n",
    "    α→Eigen value\n",
    "\n",
    "    Eigen decomposition of ‘A’ is given by \n",
    "    A=V diag(α) V (-1)/\n",
    "\n",
    "## Useful facts:\n",
    "\tThe matrix singular iff the eigen values are zero.\n",
    "\tThe matrix whose eigen values are positive is called positive definite. \n",
    "\tThe matrix with eigen values >=0 is called positive semi-definite.\n",
    "# 2.8 Singular Value Decomposition: (SVD)\n",
    "\n",
    "\tIt allows to factorise a matrix into singular vectors and singular values. It is given by A=UDVT/\n",
    "\n",
    "\t\t\tA-> mxn matrix\n",
    "\t\t\tU-> mxm matrix\n",
    "\t\t\tD-> mxn matrix\n",
    "\t\t\tV-> nxn matrix\n",
    "\n",
    "\t\tU & V are orthogonal matrices and D is the diagonal matrix.\n",
    "## Useful Insights: \n",
    "\tThe elements along diagonal D are known as singular values of matrix ‘A’.\n",
    "\tThe columns of U are known as the left-singular vectors\n",
    "\t. The columns of V are known as the right-singular vectors.\n",
    "\n",
    "# 2.9 The Moore-Penrose Pseudoinverse:\n",
    " It is defined as \n",
    "\tA+/=lim┬(a→0)⁡〖[A T/ A+αI](-1)/〗 A T/\n",
    "\n",
    "Formula \n",
    "A+/=VD +/ U T/\n",
    "U,D & V are SVD of A.\n",
    "\n",
    " \n",
    "# 2.11 Determinent:\n",
    " \tThe Det(A) is the function that maps matrices to real scalars.\n",
    "\tIf det(A)=0, the spaces is contracted completely along atleast one dimension.\n",
    "  \tIf det(A) =1,  then transformation preserves volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II b Probability and Information Theory\n",
    "\n",
    "# 3.1   Why Probability:\n",
    "    Probability is important in Machine Learning as it always deals with uncertain quantities \n",
    "\n",
    "    Possible sources of uncertenity\n",
    "\tInherent stochasticity in the system being modeled.\n",
    "\tIncomplete observability\n",
    "\tIncomplete Modelling\n",
    "\n",
    "# 3.2 Random Variables:\n",
    "\tIt is a variable that takes random values.\n",
    "# 3.3 Probability Distribution:\n",
    "\tIt is a description of now likely a randomly variable is to take on each possible states.\n",
    "  \tDiscrete Variables and Probability mass function:\n",
    "\tProbability distributions are described using Probability Density function  rather that PMF. It must satisfy the following properties:\n",
    "\tThe domain of p must be the set of all possible states of x.\n",
    "• ∀x ∈ x, p(x) ≥ 0. Note that we do not require p(x) ≤ 1.\n",
    "•∫▒〖p(x)dx = 1〗\n",
    "\n",
    "# 3.4 Marginal Probability:\n",
    "\n",
    "\tFor discrete random variables  P(x) is defined as:\n",
    "∀x∈x,P(x=x)=∑_y▒P(x=x,y=y) \n",
    " \n",
    "\tFor continuous variables  P(x) is defined as:\n",
    "\n",
    "P(x)=∫▒〖P(x,y)dy.〗\n",
    "\n",
    "# Conditional Probability:\n",
    "\n",
    "P(y=y/ x=x)=(P(y=y,x=x))/(P(x=x))\n",
    "\n",
    "\tThe conditional probability is nothing but the probability of X given the probability of Y.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
